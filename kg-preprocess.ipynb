{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess the daycare data and save biom tables and mapping files\n",
    "We load the data from 2 runs, aggregate, normalize/rarify, join, and add qiime generated taxonomy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import calour as ca\n",
    "import calour_utils as cu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import scipy\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import pandas as pd\n",
    "import scipy as sp;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/amnon/git/paper-daycare'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "ca.set_log_level(11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "db=ca.database._get_database_class('dbbact')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NOTE: since the runs contain other samples as well, the run output is not included in the git repo\n",
    "## We have saved in the git repo the resulting joined tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the data\n",
    "## we have 2 runs, with some samples duplicated between the two runs\n",
    "## so we load without normalization/filtering, then aggregate by sum and then filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ca.set_log_level('ERROR')\n",
    "dat=ca.read_amplicon('data/16S_DB1-10.biom','data/DB7_10_11_ganim_amnon_map_14July.txt',normalize=None,min_reads=500)\n",
    "ca.set_log_level('INFO')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ca.set_log_level('ERROR')\n",
    "dat2=ca.read_amplicon('data/all.db11.biom','data/DB7_10_11_ganim_amnon_map_14July.txt',normalize=None,min_reads=500)\n",
    "ca.set_log_level('INFO')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## get rid of samples not in mapping file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat=dat.filter_samples('BarcodeSequence',None)\n",
    "dat2=dat2.filter_samples('BarcodeSequence',None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## combine the 2 runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat=dat.join_experiments(dat2,'orig_run')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AmpliconExperiment (\"join  & \") with 271 samples, 14052 features"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Join samples with same sample_ID (i.e. rerun of same sample in the 2 runs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AmpliconExperiment (\"join  & \") with 268 samples, 14052 features"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat=dat.aggregate_by_metadata('sample_ID',agg='mean')\n",
    "dat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get rid of non-child samples (family members)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AmpliconExperiment (\"join  & \") with 268 samples, 14052 features"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat=dat.filter_samples('kindergarten','Family',negate=True)\n",
    "dat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sort by timepoint, and within each timepoint by subjectID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat=dat.sort_samples('pn_ID')\n",
    "dat=dat.sort_samples('Time')\n",
    "dat=dat.sort_samples('kindergarten')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the non-normalized/rarified table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-08-16 16:12:34 INFO Metadata field taxonomy not found. Saving biom table without metadata\n"
     ]
    }
   ],
   "source": [
    "dat.save('data/gan-joined')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# *** Analysis can be recreated from this point"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reload the data and add the qiime2 generated taxonomy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "ca.set_log_level('ERROR')\n",
    "dat=ca.read_amplicon('data/gan-joined.biom', sample_metadata_file='data/gan-joined_sample.txt', feature_metadata_file='data/taxonomy-all.tsv',\n",
    "                     min_reads=0, normalize=None)\n",
    "ca.set_log_level('INFO')\n",
    "dat.feature_metadata['taxonomy']=dat.feature_metadata['Taxon']\n",
    "dat=dat.split_taxonomy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# get rid of samples with not enough reads\n",
    "## How many samples do we lose for different read-depths?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "nreads=np.sum(dat.get_data(sparse=False),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min reads 0: num samples deleted 0\n",
      "min reads 1000: num samples deleted 0\n",
      "min reads 2000: num samples deleted 0\n",
      "min reads 3000: num samples deleted 0\n",
      "min reads 4000: num samples deleted 0\n",
      "min reads 5000: num samples deleted 6\n",
      "min reads 6000: num samples deleted 11\n",
      "min reads 7000: num samples deleted 22\n"
     ]
    }
   ],
   "source": [
    "for i in range(8):\n",
    "    print('min reads %d: num samples deleted %d' % (i*1000, np.sum(nreads<i*1000)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AmpliconExperiment with 268 samples, 14052 features"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We choose the threshold to be 4000 (so we lose 0 samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat=dat.reorder(nreads>=4000,axis='s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare the normalized biom table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalize to 10k reads/sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "gan=dat.normalize(10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get rid of features with <10 reads total over all samples, and cluster the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-07-03 19:45:35 INFO After filtering, 928 remain.\n",
      "2021-07-03 19:45:35 INFO After filtering, 928 remain.\n"
     ]
    }
   ],
   "source": [
    "gan=gan.filter_sum_abundance(10)\n",
    "gan=gan.cluster_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AmpliconExperiment with 268 samples, 928 features"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the normalized biom table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "gan.save('data/gan-normalized')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### and save the fasta file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "gan.save_fasta('data/gan-normalized.fa')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare the subsampled (rarified) table for the alpha-diversity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subsample to 4000 reads/sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat.data=dat.data.astype(int)\n",
    "dat_subsampled=dat.subsample_count(4000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_subsampled.sample_metadata['numSpecies']=np.sum(dat_subsampled.data>0,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AmpliconExperiment with 268 samples, 14052 features"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat_subsampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_subsampled.save('data/gan-subsampled')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
