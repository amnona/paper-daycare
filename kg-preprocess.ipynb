{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess the kindergarten data and save biom tables and mapping files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/amnon/miniconda3/envs/calour/lib/python3.7/site-packages/skbio/util/_testing.py:15: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
      "  import pandas.util.testing as pdt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "failed to load logging config file\n"
     ]
    }
   ],
   "source": [
    "import calour as ca\n",
    "import calour_utils as cu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import scipy\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import pandas as pd\n",
    "import scipy as sp;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/amnon/Projects/sheba/ortal-kindergarten'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ca.set_log_level(11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "db=ca.database._get_database_class('dbbact')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the data\n",
    "## we have 2 runs, with some samples duplicated between the two runs\n",
    "## so we load without normalization/filtering, then aggregate by sum and then filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ca.set_log_level('ERROR')\n",
    "dat=ca.read_amplicon('data/16S_DB1-10.biom','data/DB7_10_11_ganim_amnon_map_14July.txt',normalize=None,min_reads=500)\n",
    "ca.set_log_level('INFO')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ca.set_log_level('ERROR')\n",
    "dat2=ca.read_amplicon('data/all.db11.biom','data/DB7_10_11_ganim_amnon_map_14July.txt',normalize=None,min_reads=500)\n",
    "ca.set_log_level('INFO')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## get rid of samples not in mapping file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat=dat.filter_samples('BarcodeSequence',None)\n",
    "dat2=dat2.filter_samples('BarcodeSequence',None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## combine the 2 runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat=dat.join_experiments(dat2,'orig_run')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AmpliconExperiment (\"join  & \") with 271 samples, 14052 features"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Join samples with same sample_ID (i.e. rerun of same sample in the 2 runs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AmpliconExperiment (\"join  & \") with 268 samples, 14052 features"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat=dat.aggregate_by_metadata('sample_ID',agg='mean')\n",
    "dat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get rid of non-child samples (family members)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AmpliconExperiment (\"join  & \") with 268 samples, 14052 features"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat=dat.filter_samples('kindergarten','Family',negate=True)\n",
    "dat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sort by timepoint, and within each timepoint by subjectID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat=dat.sort_samples('pn_ID')\n",
    "dat=dat.sort_samples('Time')\n",
    "dat=dat.sort_samples('kindergarten')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the non-normalized/rarified table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-08-16 16:12:34 INFO Metadata field taxonomy not found. Saving biom table without metadata\n"
     ]
    }
   ],
   "source": [
    "dat.save('data/gan-joined')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# get rid of samples with not enough reads\n",
    "## How many samples do we lose for different read-depths?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "nreads=np.sum(dat.get_data(),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min reads 0: num samples deleted 0\n",
      "min reads 1000: num samples deleted 0\n",
      "min reads 2000: num samples deleted 0\n",
      "min reads 3000: num samples deleted 0\n",
      "min reads 4000: num samples deleted 0\n",
      "min reads 5000: num samples deleted 6\n",
      "min reads 6000: num samples deleted 11\n",
      "min reads 7000: num samples deleted 22\n"
     ]
    }
   ],
   "source": [
    "for i in range(8):\n",
    "    print('min reads %d: num samples deleted %d' % (i*1000, np.sum(nreads<i*1000)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AmpliconExperiment (\"join  & \") with 268 samples, 14052 features"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We choose the threshold to be 4000 (so we lose 0 samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat=dat.reorder(nreads>=4000,axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare the normalized biom table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalize to 10k reads/sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "gan=dat.normalize(10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get rid of features with <10 reads total over all samples, and cluster the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-08-16 16:12:37 INFO After filtering, 928 remain.\n",
      "2020-08-16 16:12:37 INFO After filtering, 928 remain.\n"
     ]
    }
   ],
   "source": [
    "gan=gan.filter_sum_abundance(10)\n",
    "gan=gan.cluster_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AmpliconExperiment (\"join  & \") with 268 samples, 928 features"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the normalized biom table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-08-16 16:12:38 INFO Metadata field taxonomy not found. Saving biom table without metadata\n"
     ]
    }
   ],
   "source": [
    "gan.save('data/gan-normalized')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### and save the fasta file for adding qiime2 taxonomy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "gan.save_fasta('data/gan-normalized.fa')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The output of the qiime2 taxonomy is in data/taxonomy.fa\n",
    "We load it using the feature_metadata_file parameter of read_amplicon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare the subsampled (rarified) table for the alpha-diversity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subsample to 4000 reads/sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat.data=dat.data.astype(int)\n",
    "dat_subsampled=dat.subsample_count(4000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_subsampled.sample_metadata['numSpecies']=np.sum(dat_subsampled.data>0,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AmpliconExperiment (\"join  & \") with 268 samples, 14052 features"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat_subsampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-08-16 16:12:39 INFO Metadata field taxonomy not found. Saving biom table without metadata\n"
     ]
    }
   ],
   "source": [
    "dat_subsampled.save('data/gan-subsampled')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
